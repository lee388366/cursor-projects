if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("DESeq2")
# 4. SMOTE 过采样
set.seed(42)
df_df <- as.data.frame(df)  # 转为data.frame
library(keras)
install_keras()
library(tensorflow)
library(smotefamily)         # SMOTE
library(smotefamily)         # SMOTE
library(keras)
library(data.table)
library(dplyr)
library(keras)
library(tensorflow)
library(smotefamily)         # SMOTE
library(ggplot2)
library(reticulate)
library(iml)           # SHAP解释
library(tensorflow)
tf_config()
# 1. 读取数据
setwd("/Users/liangmenglin/Cursor")
df <- data.table::fread("126case.csv")
df <- fread("126case.csv")
# 2. 数据预处理
label_col <- "survive_die"
df[[label_col]] <- as.factor(df[[label_col]])
# 检查缺失值
print(colSums(is.na(df)))
df <- na.omit(df)
# 4. SMOTE 过采样
set.seed(42)
df_df <- as.data.frame(df)  # 转为data.frame
smote_result <- SMOTE(df_df[ , !(names(df_df) %in% label_col)], df_df[[label_col]], K = 5)
df_smote <- smote_result$data
# smotefamily会自动把最后一列命名为class
X <- as.matrix(df_smote[ , -ncol(df_smote)])
y <- as.numeric(df_smote$class) - 1  # 变成0/1
# 5. 划分训练集、验证集、测试集
set.seed(42)
n <- nrow(X)
train_idx <- sample(1:n, size = floor(0.7 * n))
val_idx <- sample(setdiff(1:n, train_idx), size = floor(0.15 * n))
test_idx <- setdiff(1:n, c(train_idx, val_idx))
X_train <- X[train_idx, ]
y_train <- y[train_idx]
X_val <- X[val_idx, ]
y_val <- y[val_idx]
X_test <- X[test_idx, ]
y_test <- y[test_idx]
library(keras)
install_tensorflow()
brew install python@3.11
which python3.11
library(reticulate)
use_python("/opt/homebrew/bin/python3.11", required = TRUE)
conda_create("r-tensorflow", python_version = "3.11")
conda_create("r-tensorflow", python_version = "3.13")
use_condaenv("r-tensorflow", required = TRUE)
library(Anaconda)
library(reticulate)
conda_create("r-tensorflow", python_version = "3.13")
library(reticulate)
use_python("/opt/homebrew/bin/python3.11", required = TRUE)
library(keras)
install_tensorflow()
library(keras)
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = ncol(X_train)) %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 1, activation = "sigmoid")
# 6. 构建深度学习模型
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = ncol(X_train)) %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = "accuracy"
)
